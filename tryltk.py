import nltk
from nltk.tokenize import RegexpTokenizer
#from nltk.book import text1


#text1.concordance("monstrous")
hu = 'expected string or bytes-like object'

text = nltk.word_tokenize(text1)
print(text)
#print(len(nltk.word_tokenize(text1)))